[interface]
classification = database / manipulation

[parameters]
; Name of the chado database to be affected.
$;DATABASE$; = $;PROJECT$;
; The name of the server on which the database resides.
$;SERVER$; =
; Relational database management system type e.g. sybase or postgresql
$;RDBMS$; = sybase
$;USERNAME$; =
$;PASSWORD$; = 
; The chado-mart table BCP files will be gzipped.
$;GZIP_BCP$;=1
; The analysis_id to which all blast data is tied to.
; The create_blast_query_view_bcp.pl script will generate BCP records
; to be loaded into the chado-mart table: cm_blast. This value will also be used
; to generate the cm_clusters statistics so it should correspond to the analysis used
; to generate the clusters.
$;BLAST_ANALYSIS_ID$;=
; The analysis_id associated with the data to be prepared for insertion into the chado-mart tables.
; This parameter can accept comma separated lists: 4,5,6. Alternatively, the user can specify the 
; program.  If both are provided, the analysis_id will
; override the program value.  The chadoToChadoMart.pl program will generate BCP records to be 
; loaded into the chado-mart tables: cm_proteins, cm_clusters, cm_cluster_members.
$;CLUSTER_ANALYSIS_ID$;=
$;PROGRAM$;=
;; Sybase bcp utility batch size
$;BCP_BATCH_SIZE$; = 30000
; Utilize a prepopulated cm_blast table to generate the cm_cluster records. This is quite fast for large
; data sets provided the cm_blast table is populated correctly and the indices are in place.
$;USE_CM_BLAST$; = 0

[input]

[output]
$;OUTPUT_TOKEN$; = default
$;OUTPUT_DIRECTORY$;=$;TMP_DIR$;

[component]
$;COMPONENT_NAME$; = refresh_chado_mart
$;DESCRIPTION$; = none
$;WORKFLOW_REPOSITORY$; = $;REPOSITORY_ROOT$;/workflow/runtime/$;COMPONENT_NAME$;/$;PIPELINEID$;_$;OUTPUT_TOKEN$;
$;PIPELINE_TOKEN$; = unnamed

;The version,revision,tag here is set by an interpolated CVS tag
$;VERSION$; = 2.0
$;RELEASE_TAG$; = $Name$
$;REVISION$;            = $Revision: 4794 $

$;TEMPLATE_XML$; = $;DOCS_DIR$;/$;COMPONENT_NAME$;.xml

$;ITERATOR1$; = truncate
$;ITERATOR1_XML$; = $;DOCS_DIR$;/$;COMPONENT_NAME$;.sqlforce.xml
$;ITERATOR2$; = drop_indices
$;ITERATOR2_XML$; = $;DOCS_DIR$;/$;COMPONENT_NAME$;.sqlforce.xml
$;ITERATOR3$; = load
$;ITERATOR3_XML$; = $;DOCS_DIR$;/$;COMPONENT_NAME$;.load.xml
$;ITERATOR4$; = create_indices
$;ITERATOR4_XML$; = $;DOCS_DIR$;/$;COMPONENT_NAME$;.sqlforce.xml


;Distributed options
$;GROUP_COUNT$; = 1
; no-distrib = 0 ensures that all executes in series and never parallel
$;NODISTRIB$; = 0

;the following keys are replaced at runtime by the invocation script
$;COMPONENT_CONFIG$; = 
$;COMPONENT_XML$; = 
$;PIPELINE_XML$; = 
$;PIPELINEID$; = 

[include]
$;PROJECT_CONFIG$;=
